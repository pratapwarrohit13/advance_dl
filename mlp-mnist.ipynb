{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-30T03:50:28.977844Z","iopub.execute_input":"2021-07-30T03:50:28.978361Z","iopub.status.idle":"2021-07-30T03:50:28.991456Z","shell.execute_reply.started":"2021-07-30T03:50:28.978249Z","shell.execute_reply":"2021-07-30T03:50:28.990510Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout,Conv2D,Flatten\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.optimizers import RMSprop\n","metadata":{"execution":{"iopub.status.busy":"2021-07-30T04:18:20.234000Z","iopub.execute_input":"2021-07-30T04:18:20.234363Z","iopub.status.idle":"2021-07-30T04:18:20.240314Z","shell.execute_reply.started":"2021-07-30T04:18:20.234335Z","shell.execute_reply":"2021-07-30T04:18:20.239182Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"(features_train, target_train), (features_test, target_test) = mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T03:52:37.399758Z","iopub.execute_input":"2021-07-30T03:52:37.400177Z","iopub.status.idle":"2021-07-30T03:52:37.734367Z","shell.execute_reply.started":"2021-07-30T03:52:37.400142Z","shell.execute_reply":"2021-07-30T03:52:37.733351Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"num_labels = len(np.unique(target_train))\n\n# convert to one-hot vector\ntarget_train = to_categorical(target_train)\ntarget_test = to_categorical(target_test)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-30T03:52:59.198588Z","iopub.execute_input":"2021-07-30T03:52:59.199113Z","iopub.status.idle":"2021-07-30T03:52:59.208700Z","shell.execute_reply.started":"2021-07-30T03:52:59.199082Z","shell.execute_reply":"2021-07-30T03:52:59.207843Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# image dimensions (assumed square)\nimage_size = features_train.shape[1]\ninput_size = image_size * image_size","metadata":{"execution":{"iopub.status.busy":"2021-07-30T03:53:48.522763Z","iopub.execute_input":"2021-07-30T03:53:48.523257Z","iopub.status.idle":"2021-07-30T03:53:48.527279Z","shell.execute_reply.started":"2021-07-30T03:53:48.523227Z","shell.execute_reply":"2021-07-30T03:53:48.526233Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"features_train = np.reshape(features_train, [-1, input_size])\nfeatures_train = features_train.astype('float32') / 255\nfeatures_test = np.reshape(features_test, [-1, input_size])\nfeatures_test = features_test.astype('float32') / 255","metadata":{"execution":{"iopub.status.busy":"2021-07-30T03:54:52.454785Z","iopub.execute_input":"2021-07-30T03:54:52.455150Z","iopub.status.idle":"2021-07-30T03:54:52.560465Z","shell.execute_reply.started":"2021-07-30T03:54:52.455121Z","shell.execute_reply":"2021-07-30T03:54:52.559584Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\nhidden_units = 256\ndropout = 0.45","metadata":{"execution":{"iopub.status.busy":"2021-07-30T03:55:02.707893Z","iopub.execute_input":"2021-07-30T03:55:02.708274Z","iopub.status.idle":"2021-07-30T03:55:02.712159Z","shell.execute_reply.started":"2021-07-30T03:55:02.708245Z","shell.execute_reply":"2021-07-30T03:55:02.711401Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(hidden_units, input_dim=input_size))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(hidden_units))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(dropout))\nmodel.add(Dense(num_labels))\n# this is the output for one-hot vector\nmodel.add(Activation('softmax'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-30T03:55:13.046902Z","iopub.execute_input":"2021-07-30T03:55:13.047319Z","iopub.status.idle":"2021-07-30T03:55:13.170999Z","shell.execute_reply.started":"2021-07-30T03:55:13.047285Z","shell.execute_reply":"2021-07-30T03:55:13.170292Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 256)               200960    \n_________________________________________________________________\nactivation (Activation)      (None, 256)               0         \n_________________________________________________________________\ndropout (Dropout)            (None, 256)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 256)               65792     \n_________________________________________________________________\nactivation_1 (Activation)    (None, 256)               0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                2570      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 10)                0         \n=================================================================\nTotal params: 269,322\nTrainable params: 269,322\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.fit(features_train, target_train, epochs=200, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-07-30T03:56:36.881749Z","iopub.execute_input":"2021-07-30T03:56:36.882150Z","iopub.status.idle":"2021-07-30T04:04:19.950961Z","shell.execute_reply.started":"2021-07-30T03:56:36.882117Z","shell.execute_reply":"2021-07-30T04:04:19.949921Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/200\n469/469 [==============================] - 3s 5ms/step - loss: 0.7252 - accuracy: 0.7677\nEpoch 2/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.2076 - accuracy: 0.9358\nEpoch 3/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.1604 - accuracy: 0.9509\nEpoch 4/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.1326 - accuracy: 0.9594\nEpoch 5/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.1133 - accuracy: 0.9658\nEpoch 6/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0987 - accuracy: 0.9686\nEpoch 7/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0932 - accuracy: 0.9705\nEpoch 8/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0827 - accuracy: 0.9736\nEpoch 9/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0784 - accuracy: 0.9745\nEpoch 10/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0758 - accuracy: 0.9757\nEpoch 11/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0761 - accuracy: 0.9753\nEpoch 12/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0670 - accuracy: 0.9786\nEpoch 13/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0643 - accuracy: 0.9788\nEpoch 14/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0652 - accuracy: 0.9797\nEpoch 15/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0597 - accuracy: 0.9806\nEpoch 16/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0592 - accuracy: 0.9807\nEpoch 17/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0536 - accuracy: 0.9823\nEpoch 18/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0536 - accuracy: 0.9820\nEpoch 19/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0535 - accuracy: 0.9824\nEpoch 20/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0531 - accuracy: 0.9838\nEpoch 21/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0520 - accuracy: 0.9829\nEpoch 22/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0514 - accuracy: 0.9837\nEpoch 23/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0476 - accuracy: 0.9849\nEpoch 24/200\n469/469 [==============================] - 3s 6ms/step - loss: 0.0501 - accuracy: 0.9836\nEpoch 25/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0492 - accuracy: 0.9840\nEpoch 26/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0478 - accuracy: 0.9846\nEpoch 27/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0434 - accuracy: 0.9850\nEpoch 28/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9868\nEpoch 29/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0403 - accuracy: 0.9863\nEpoch 30/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0424 - accuracy: 0.9866\nEpoch 31/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0430 - accuracy: 0.9865\nEpoch 32/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0411 - accuracy: 0.9869\nEpoch 33/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9873\nEpoch 34/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.9876\nEpoch 35/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0392 - accuracy: 0.9874\nEpoch 36/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0394 - accuracy: 0.9870\nEpoch 37/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0337 - accuracy: 0.9887\nEpoch 38/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0385 - accuracy: 0.9878\nEpoch 39/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0334 - accuracy: 0.9892\nEpoch 40/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0377 - accuracy: 0.9876\nEpoch 41/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0384 - accuracy: 0.9876\nEpoch 42/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0351 - accuracy: 0.9886\nEpoch 43/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0370 - accuracy: 0.9876\nEpoch 44/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0348 - accuracy: 0.9887\nEpoch 45/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0350 - accuracy: 0.9886\nEpoch 46/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0357 - accuracy: 0.9890\nEpoch 47/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0335 - accuracy: 0.9888\nEpoch 48/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0323 - accuracy: 0.9898\nEpoch 49/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0354 - accuracy: 0.9886\nEpoch 50/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0315 - accuracy: 0.9899\nEpoch 51/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0316 - accuracy: 0.9896\nEpoch 52/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0356 - accuracy: 0.9877\nEpoch 53/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0367 - accuracy: 0.9880\nEpoch 54/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0289 - accuracy: 0.9909\nEpoch 55/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0318 - accuracy: 0.9892\nEpoch 56/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0332 - accuracy: 0.9891\nEpoch 57/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0361 - accuracy: 0.9884\nEpoch 58/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0332 - accuracy: 0.9894\nEpoch 59/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0307 - accuracy: 0.9903\nEpoch 60/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0295 - accuracy: 0.9910\nEpoch 61/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0328 - accuracy: 0.9901\nEpoch 62/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0320 - accuracy: 0.9902\nEpoch 63/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0309 - accuracy: 0.9900\nEpoch 64/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0292 - accuracy: 0.9910\nEpoch 65/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0283 - accuracy: 0.9906\nEpoch 66/200\n469/469 [==============================] - 3s 5ms/step - loss: 0.0303 - accuracy: 0.9900\nEpoch 67/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0315 - accuracy: 0.9905\nEpoch 68/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0272 - accuracy: 0.9916\nEpoch 69/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0296 - accuracy: 0.9901\nEpoch 70/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0271 - accuracy: 0.9909\nEpoch 71/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0269 - accuracy: 0.9915\nEpoch 72/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0275 - accuracy: 0.9912\nEpoch 73/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0274 - accuracy: 0.9910\nEpoch 74/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0283 - accuracy: 0.9908\nEpoch 75/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0271 - accuracy: 0.9914\nEpoch 76/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0264 - accuracy: 0.9917\nEpoch 77/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0307 - accuracy: 0.9909\nEpoch 78/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0246 - accuracy: 0.9918\nEpoch 79/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0314 - accuracy: 0.9898\nEpoch 80/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.9924\nEpoch 81/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0295 - accuracy: 0.9906\nEpoch 82/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0240 - accuracy: 0.9923\nEpoch 83/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0283 - accuracy: 0.9911\nEpoch 84/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0256 - accuracy: 0.9917\nEpoch 85/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0315 - accuracy: 0.9902\nEpoch 86/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0274 - accuracy: 0.9908\nEpoch 87/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0235 - accuracy: 0.9926\nEpoch 88/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0289 - accuracy: 0.9914\nEpoch 89/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0265 - accuracy: 0.9918\nEpoch 90/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9930\nEpoch 91/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0248 - accuracy: 0.9925\nEpoch 92/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0262 - accuracy: 0.9924\nEpoch 93/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0245 - accuracy: 0.9921\nEpoch 94/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0270 - accuracy: 0.9914\nEpoch 95/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.9919\nEpoch 96/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0253 - accuracy: 0.9925\nEpoch 97/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0235 - accuracy: 0.9924\nEpoch 98/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0251 - accuracy: 0.9922\nEpoch 99/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9933\nEpoch 100/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.9919\nEpoch 101/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0247 - accuracy: 0.9923\nEpoch 102/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0318 - accuracy: 0.9907\nEpoch 103/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9929\nEpoch 104/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0275 - accuracy: 0.9918\nEpoch 105/200\n469/469 [==============================] - 3s 6ms/step - loss: 0.0232 - accuracy: 0.9928\nEpoch 106/200\n469/469 [==============================] - 3s 6ms/step - loss: 0.0251 - accuracy: 0.9921\nEpoch 107/200\n469/469 [==============================] - 3s 6ms/step - loss: 0.0239 - accuracy: 0.9924\nEpoch 108/200\n469/469 [==============================] - 3s 7ms/step - loss: 0.0258 - accuracy: 0.9921\nEpoch 109/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0235 - accuracy: 0.9929\nEpoch 110/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0233 - accuracy: 0.9928\nEpoch 111/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0230 - accuracy: 0.9928\nEpoch 112/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0247 - accuracy: 0.9922\nEpoch 113/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0198 - accuracy: 0.9939\nEpoch 114/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9927\nEpoch 115/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0252 - accuracy: 0.9925\nEpoch 116/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0254 - accuracy: 0.9923\nEpoch 117/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.9923\nEpoch 118/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0234 - accuracy: 0.9929\nEpoch 119/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0239 - accuracy: 0.9933\nEpoch 120/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9930\nEpoch 121/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0244 - accuracy: 0.9931\nEpoch 122/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9927\nEpoch 123/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0263 - accuracy: 0.9918\nEpoch 124/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9918\nEpoch 125/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0221 - accuracy: 0.9929\nEpoch 126/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.9927\nEpoch 127/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9930\nEpoch 128/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0216 - accuracy: 0.9936\nEpoch 129/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0261 - accuracy: 0.9918\nEpoch 130/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0220 - accuracy: 0.9933\nEpoch 131/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0198 - accuracy: 0.9939\nEpoch 132/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0206 - accuracy: 0.9943\nEpoch 133/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0226 - accuracy: 0.9933\nEpoch 134/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0198 - accuracy: 0.9938\nEpoch 135/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0231 - accuracy: 0.9930\nEpoch 136/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0214 - accuracy: 0.9941\nEpoch 137/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0197 - accuracy: 0.9941\nEpoch 138/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0241 - accuracy: 0.9935\nEpoch 139/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0218 - accuracy: 0.9937\nEpoch 140/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0195 - accuracy: 0.9939\nEpoch 141/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0212 - accuracy: 0.9934\nEpoch 142/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0270 - accuracy: 0.9925\nEpoch 143/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0219 - accuracy: 0.9930\nEpoch 144/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9931\nEpoch 145/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9934\nEpoch 146/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0227 - accuracy: 0.9932\nEpoch 147/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0218 - accuracy: 0.9933\nEpoch 148/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0229 - accuracy: 0.9928\nEpoch 149/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9936\nEpoch 150/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0238 - accuracy: 0.9928\nEpoch 151/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0235 - accuracy: 0.9926\nEpoch 152/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9935\nEpoch 153/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0197 - accuracy: 0.9939\nEpoch 154/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9933\nEpoch 155/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0187 - accuracy: 0.9941\nEpoch 156/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9937\nEpoch 157/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9940\nEpoch 158/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0197 - accuracy: 0.9941\nEpoch 159/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0237 - accuracy: 0.9934\nEpoch 160/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0219 - accuracy: 0.9934\nEpoch 161/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0198 - accuracy: 0.9942\nEpoch 162/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0243 - accuracy: 0.9925\nEpoch 163/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0169 - accuracy: 0.9945\nEpoch 164/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0192 - accuracy: 0.9941\nEpoch 165/200\n469/469 [==============================] - 3s 5ms/step - loss: 0.0196 - accuracy: 0.9943\nEpoch 166/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9937\nEpoch 167/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9939\nEpoch 168/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0189 - accuracy: 0.9947\nEpoch 169/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0223 - accuracy: 0.9934\nEpoch 170/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0221 - accuracy: 0.9940\nEpoch 171/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0192 - accuracy: 0.9944\nEpoch 172/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0232 - accuracy: 0.9926\nEpoch 173/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0212 - accuracy: 0.9932\nEpoch 174/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0194 - accuracy: 0.9943\nEpoch 175/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0207 - accuracy: 0.9932\nEpoch 176/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0222 - accuracy: 0.9935\nEpoch 177/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0205 - accuracy: 0.9939\nEpoch 178/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0177 - accuracy: 0.9943\nEpoch 179/200\n469/469 [==============================] - 3s 5ms/step - loss: 0.0186 - accuracy: 0.9945\nEpoch 180/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0189 - accuracy: 0.9942\nEpoch 181/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0204 - accuracy: 0.9938\nEpoch 182/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0217 - accuracy: 0.9938\nEpoch 183/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0194 - accuracy: 0.9941\nEpoch 184/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0169 - accuracy: 0.9948\nEpoch 185/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0177 - accuracy: 0.9946\nEpoch 186/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0244 - accuracy: 0.9942\nEpoch 187/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0195 - accuracy: 0.9942\nEpoch 188/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0263 - accuracy: 0.9927\nEpoch 189/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0197 - accuracy: 0.9939\nEpoch 190/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0240 - accuracy: 0.9931\nEpoch 191/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0161 - accuracy: 0.9951\nEpoch 192/200\n469/469 [==============================] - 3s 6ms/step - loss: 0.0200 - accuracy: 0.9943\nEpoch 193/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0199 - accuracy: 0.9943\nEpoch 194/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0176 - accuracy: 0.9949\nEpoch 195/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0186 - accuracy: 0.9944\nEpoch 196/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0204 - accuracy: 0.9945\nEpoch 197/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0182 - accuracy: 0.9941\nEpoch 198/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0209 - accuracy: 0.9938\nEpoch 199/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0201 - accuracy: 0.9941\nEpoch 200/200\n469/469 [==============================] - 2s 5ms/step - loss: 0.0206 - accuracy: 0.9948\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fa72f9f22d0>"},"metadata":{}}]},{"cell_type":"code","source":"_, acc = model.evaluate(features_test,\n                        target_test,\n                        batch_size=batch_size,\n                        verbose=0)\nprint(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))","metadata":{"execution":{"iopub.status.busy":"2021-07-30T04:04:19.952817Z","iopub.execute_input":"2021-07-30T04:04:19.953158Z","iopub.status.idle":"2021-07-30T04:04:20.337946Z","shell.execute_reply.started":"2021-07-30T04:04:19.953122Z","shell.execute_reply":"2021-07-30T04:04:20.336967Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nTest accuracy: 98.5%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}